{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "\n",
    "DBSCAN is a density-based clustering algorithm that groups together points that are close to each other based on a distance metric and a density threshold, while marking points that are in low-density regions as noise.\n",
    "\n",
    "## History\n",
    "\n",
    "DBSCAN was proposed by Martin Ester, Hans-Peter Kriegel, JÃ¶rg Sander, and Xiaowei Xu in 1996. The algorithm has since become a popular choice for clustering tasks due to its ability to find clusters of arbitrary shapes and its robustness to noise.\n",
    "\n",
    "## Mathematical Equations\n",
    "\n",
    "DBSCAN does not rely on a specific mathematical equation like some other machine learning algorithms. Instead, it is based on the concept of density, which is defined as the number of points within a given radius `eps` of a point.\n",
    "\n",
    "## Learning Algorithm\n",
    "\n",
    "The learning algorithm for DBSCAN consists of the following steps:\n",
    "\n",
    "1. For each point in the dataset, determine the points within the `eps` radius.\n",
    "2. If a point has at least `min_samples` points within its `eps` radius, mark it as a core point. Otherwise, mark it as a border point or noise.\n",
    "3. Assign each point to a cluster by following the procedure:\n",
    "   - If a point is a core point, create a new cluster and recursively add all directly and indirectly reachable core points within the `eps` radius.\n",
    "   - If a point is a border point, assign it to the nearest core point's cluster.\n",
    "   - If a point is noise, do not assign it to any cluster.\n",
    "\n",
    "The `eps` radius and `min_samples` are hyperparameters of the DBSCAN algorithm.\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- Can find clusters of arbitrary shapes.\n",
    "- Robust to noise.\n",
    "- Does not require the number of clusters as an input parameter.\n",
    "- Handles datasets with varying densities.\n",
    "- Requires only two hyperparameters.\n",
    "\n",
    "**Cons:**\n",
    "- Not efficient with high-dimensional data.\n",
    "- Sensitive to the choice of `eps` and `min_samples` hyperparameters.\n",
    "- Cannot handle clusters with different densities well.\n",
    "\n",
    "## Suitable Tasks and Datasets\n",
    "\n",
    "DBSCAN can be applied to a variety of clustering tasks, including:\n",
    "\n",
    "- Anomaly detection\n",
    "- Image segmentation\n",
    "- Spatial data analysis\n",
    "- Pattern recognition\n",
    "\n",
    "It works well with datasets that have clusters of arbitrary shapes and varying densities. DBSCAN is also suitable for datasets with noise.\n",
    "\n",
    "## Difference between K-means and DBSCAN\n",
    "\n",
    "The main differences between k-means and DBSCAN are:\n",
    "\n",
    "- K-means requires the number of clusters as an input parameter, while DBSCAN does not.\n",
    "- K-means is sensitive to the initial placement of centroids and may converge to local optima, while DBSCAN is more robust due to its density-based approach.\n",
    "- K-means tends to work well with spherical clusters and may struggle with clusters of arbitrary shapes, while DBSCAN can find clusters of any shape.\n",
    "- K-means is less robust to noise compared to DBSCAN, which can identify and separate noise points from clusters.\n",
    "- DBSCAN can handle datasets with varying densities, while k-means assumes similar densities across clusters.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Ester, M., Kriegel, H. P., Sander, J., & Xu, X. (1996). A density-based algorithm for discovering clusters in large spatial databases with noise. In Kdd (Vol. 96, No. 34, pp. 226-231).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from collections import deque\n",
    "\n",
    "# Function to calculate Euclidean distance between two points\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# DBSCAN class\n",
    "class DBSCAN:\n",
    "    def __init__(self, eps=0.5, min_samples=5):\n",
    "        self.eps = eps\n",
    "        self.min_samples = min_samples\n",
    "\n",
    "    def fit_predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        labels = np.full(n_samples, -1, dtype=int)  # -1 represents noise points\n",
    "        cluster_id = 0\n",
    "\n",
    "        for i in range(n_samples):\n",
    "            if labels[i] != -1:  # Point already assigned to a cluster\n",
    "                continue\n",
    "\n",
    "            neighbors = self._find_neighbors(X, i)\n",
    "            if len(neighbors) < self.min_samples:  # Noise point\n",
    "                continue\n",
    "\n",
    "            # Assign point and its neighbors to a new cluster\n",
    "            self._expand_cluster(X, labels, i, neighbors, cluster_id)\n",
    "            cluster_id += 1\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def _find_neighbors(self, X, i):\n",
    "        neighbors = []\n",
    "        for j, x_j in enumerate(X):\n",
    "            if euclidean_distance(X[i], x_j) <= self.eps:\n",
    "                neighbors.append(j)\n",
    "        return neighbors\n",
    "\n",
    "    def _expand_cluster(self, X, labels, i, neighbors, cluster_id):\n",
    "        labels[i] = cluster_id\n",
    "        queue = deque(neighbors)\n",
    "\n",
    "        while queue:\n",
    "            j = queue.popleft()\n",
    "            if labels[j] == -1:  # Noise point\n",
    "                labels[j] = cluster_id\n",
    "            elif labels[j] != -1:  # Point already assigned to a cluster\n",
    "                continue\n",
    "\n",
    "            new_neighbors = self._find_neighbors(X, j)\n",
    "            if len(new_neighbors) >= self.min_samples:\n",
    "                queue.extend(new_neighbors)\n",
    "\n",
    "# Generate the \"two moons\" dataset\n",
    "X, y = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
    "\n",
    "# Apply the DBSCAN algorithm\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Generate the \"two moons\" dataset\n",
    "X, y = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
    "\n",
    "# Apply the DBSCAN algorithm\n",
    "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "# Evaluate the model using silhouette score\n",
    "score = silhouette_score(X, clusters)\n",
    "print(f\"Silhouette Score: {score:.2f}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X[:, 0], X[:, 1], c=clusters, cmap='viridis')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.title('DBSCAN Clustering')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
