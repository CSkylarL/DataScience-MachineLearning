{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis (PCA)\n",
    "\n",
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Learning Algorithm](#learning-algorithm)\n",
    "    - [Define a DBSCAN class](#define-a-dbscan-class)\n",
    "    - [Showcase the above classifier in the moon dataset](#showcase-the-above-classifier-in-the-moon-dataset)\n",
    "3. [Difference between K-means and DBSCAN](#difference-between-k-means-and-dbscan)\n",
    "    - [Comparison of K-means and DBSCAN on different datasets](#comparison-of-k-means-and-dbscan-on-different-datasets)\n",
    "4. [Pros and Cons](#pros-and-cons)\n",
    "5. [Suitable Tasks and Datasets](#suitable-tasks-and-datasets)\n",
    "6. [References](#references)\n",
    "\n",
    "\n",
    "## History\n",
    "\n",
    "Principal Component Analysis (PCA) is a statistical procedure and dimensionality reduction technique that has been extensively applied in various fields of machine learning and data analysis. Introduced by Karl Pearson in 1901 and later extended by Harold Hotelling in 1933, PCA plays a crucial role in preprocessing high-dimensional data, visualizing complex data structures, and reducing noise.\n",
    "\n",
    "The core idea of PCA is to project the data onto a lower-dimensional space, such that the greatest possible amount of variance in the data is preserved. Initially, PCA was developed as a transformation method to convert observations of possibly correlated variables into a set of linearly uncorrelated variables known as principal components. This transformation is valuable as it often reveals internal structure in the data that was not immediately apparent in the high-dimensional space.\n",
    "\n",
    "In a nutshell, PCA is an efficient tool that helps deal with high-dimensionality in datasets, making it easier to extract important information while minimizing information loss.\n",
    "\n",
    "## Mathematical Foundations\n",
    "\n",
    "## Mathematical Foundations of PCA\n",
    "\n",
    "PCA is based on linear algebra and specifically on the operation of eigen decomposition or singular value decomposition of a matrix. \n",
    "\n",
    "Given a $d$-dimensional dataset, the goal is to find a $k$-dimensional subspace (where $k<d$) that captures the most variance in the data. This is done by projecting the original data points onto this subspace. \n",
    "\n",
    "The $k$ dimensions (or axes) of this subspace are vectors called principal components. These are found by solving the following optimization problem (variance maximization problem):\n",
    "\n",
    "$$\n",
    "\\max_{\\mathbf{w}} \\: \\mathbf{w}^T \\mathbf{S} \\mathbf{w} \\quad \\text{s.t.} \\quad \\mathbf{w}^T \\mathbf{w} = 1\n",
    "$$\n",
    "\n",
    "In this equation:\n",
    "\n",
    "- $\\mathbf{w}$ is the weight vector that we are trying to find. This vector will become the principal component.\n",
    "\n",
    "- $\\mathbf{S}$ is the sample covariance matrix of the data. The covariance matrix provides a measure of how much each of the dimensions/variances of the input dataset 'vary together', which is calculated as follows:\n",
    "\n",
    "    $$\n",
    "    \\mathbf{S} = \\frac{1}{N-1} \\sum_{i=1}^{N} (\\mathbf{x}_i - \\bar{\\mathbf{x}})(\\mathbf{x}_i - \\bar{\\mathbf{x}})^T\n",
    "    $$\n",
    "\n",
    "    where:\n",
    "\n",
    "    - $N$ is the number of samples in the dataset.\n",
    "    - $\\mathbf{x}_i$ represents each individual data point in the dataset.\n",
    "    - $\\bar{\\mathbf{x}}$ is the mean vector of the dataset, calculated as $\\bar{\\mathbf{x}} = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbf{x}_i$.\n",
    "\n",
    "    The covariance matrix $\\mathbf{S}$ is a $d \\times d$ matrix (where $d$ is the number of dimensions/features in your data), and each element $S_{ij} = \\frac{1}{N-1} \\sum_{n=1}^{N} (x_{ni} - \\bar{x}_i)(x_{nj} - \\bar{x}_j)$ in this matrix is the covariance between the $i^{th}$ and $j^{th}$ dimensions of the data. The diagonal elements of the covariance matrix ($S_{ii}$) are the variances of individual dimensions.\n",
    "\n",
    "\n",
    "- $\\mathbf{w}^T \\mathbf{S} \\mathbf{w}$ is the variance of the data along the direction of $\\mathbf{w}$. We want to maximize this variance, as we're seeking the direction (or principal component) that retains the maximum possible information from the original data.\n",
    "\n",
    "- The condition $\\mathbf{w}^T \\mathbf{w} = 1$ is a constraint that ensures that $\\mathbf{w}$ is a unit vector (i.e., its length is 1). This prevents trivial solutions, such as increasing the length of $\\mathbf{w}$ to artificially inflate the variance.\n",
    "\n",
    "The principal components are ordered by their corresponding `eigenvalues` which represent the amount of variance captured by each principal component. Thus, the first principal component is the direction in the data that captures the most variance, the second principal component (which is orthogonal to the first) captures the second most variance, and so on. We compute the eigenvalues ($\\lambda$) and eigenvectors ($\\mathbf{v}$) of the sample covariance matrix ($\\mathbf{S}$), which satisfy the following equation:\n",
    "\n",
    "$$\n",
    "\\mathbf{S}\\mathbf{v} = \\lambda\\mathbf{v}\n",
    "$$\n",
    "\n",
    "Again, the eigenvalues represent the variance (information) along the new feature axes, while the eigenvectors represent the directions of these new axes. The eigenvector $\\mathbf{v}$ must be non-zero.\n",
    "\n",
    "\n",
    "## Learning Algorithm\n",
    "\n",
    "The learning algorithm for PCA consists of the following steps:\n",
    "\n",
    "1. Standardize the dataset (mean = 0, standard deviation = 1) to ensure equal importance of all features.\n",
    "2. Calculate the covariance matrix of the standardized dataset.\n",
    "3. Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "4. Sort the eigenvalues in descending order and select the top k eigenvectors.\n",
    "5. Project the original data onto the lower-dimensional space spanned by the top k eigenvectors.\n",
    "\n",
    "### Define the PCA class\n",
    "### Showcase the above PCA Class in iris dataset\n",
    "### Use the PCA class provided by Scikit-Learn\n",
    "\n",
    "###\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- Reduces the dimensionality of the data, which can help overcome the curse of dimensionality and improve the performance of machine learning algorithms.\n",
    "- Can help visualize high-dimensional data.\n",
    "- Removes multicollinearity between features and improves interpretability of the results.\n",
    "- Can be used for noise reduction in the data.\n",
    "\n",
    "**Cons:**\n",
    "- Assumes that the principal components are linear combinations of the original features.\n",
    "- Loss of information due to the reduction in dimensionality.\n",
    "- Sensitive to the scaling of the features.\n",
    "\n",
    "## Suitable Tasks and Datasets\n",
    "\n",
    "PPCA is suitable for a wide variety of tasks and datasets. Here are a few examples:\n",
    "\n",
    "1. **Data Preprocessing**: PCA can be used as a preprocessing step in machine learning pipelines to reduce the dimensionality of the data. This can help mitigate the curse of dimensionality and reduce the risk of overfitting. This is particularly useful for datasets with a large number of features, i.e., high-dimensional datasets.\n",
    "\n",
    "2. **Noise Reduction**: PCA can be used to denoise data by projecting it onto a lower-dimensional space, which can effectively reduce the effect of noise variables.\n",
    "\n",
    "3. **Visualization**: PCA can be used to visualize high-dimensional data by projecting it onto a 2 or 3-dimensional space. This is helpful for datasets where it's important to understand the structure and relationships in the data.\n",
    "\n",
    "4. **Anomaly Detection**: In some cases, outliers or anomalies will become more apparent when visualized in the lower-dimensional space created by PCA.\n",
    "\n",
    "5. **Data Compression**: PCA can be used to compress data, reducing its storage requirements and speeding up learning algorithms.\n",
    "\n",
    "6. **Feature Extraction**: PCA can also be used for feature extraction. By transforming the original variables to a new set of variables, which are the principal components, PCA can extract the most important information from the dataset. These new variables are linear combinations of the original variables and can sometimes be more interpretable.\n",
    "\n",
    "Common datasets where PCA might be used include image datasets, text datasets (after converting the text into a set of numerical features), gene expression and any dataset with a large number of features. However, PCA assumes a linear relationship among variables. If this assumption is violated, the results may not be reliable.\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "1. Pearson, K. (1901). LIII. On lines and planes of closest fit to systems of points in space. The London, Edinburgh, and Dublin philosophical magazine and journal of science, 2(11), 559-572.\n",
    "2. Hotelling, H. (1933). Analysis of a complex of statistical variables into principal components. Journal of educational psychology, 24(6), 417.\n",
    "3. Scikit-Learn: Principal Component Analysis. https://scikit-learn.org/stable/modules/decomposition.html#pca\n",
    "4. GÃ©ron, A. (2022). Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow. \" O'Reilly Media, Inc.\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class PCA:\n",
    "    \"\"\"\n",
    "    Principal Component Analysis (PCA) implementation.\n",
    "\n",
    "    Attributes:\n",
    "        n_components (int): The number of components to keep.\n",
    "\n",
    "    Methods:\n",
    "        standardize(X): Standardizes the features in the dataset.\n",
    "        fit_transform(X): Fits the model with X and apply the dimensionality reduction on X.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components):\n",
    "        self.n_components = n_components\n",
    "\n",
    "    def standardize(self, X):\n",
    "        \"\"\"\n",
    "        Standardizes the features in the dataset.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): The dataset to standardize.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: The standardized dataset.\n",
    "        \"\"\"\n",
    "        # Standardize by subtracting mean and dividing by standard deviation\n",
    "        mean = np.mean(X, axis=0)\n",
    "        std = np.std(X, axis=0)\n",
    "        return (X - mean) / std\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fits the model with X and apply the dimensionality reduction on X.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy.ndarray): The input data to fit and transform.\n",
    "\n",
    "        Returns:\n",
    "            numpy.ndarray: Transformed data.\n",
    "        \"\"\"\n",
    "        # Standardize the input dataset\n",
    "        X_standardized = self.standardize(X)\n",
    "\n",
    "        # Calculate the covariance matrix\n",
    "        covariance_matrix = np.cov(X_standardized.T)\n",
    "\n",
    "        # Compute the eigenvalues and eigenvectors\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)\n",
    "\n",
    "        # Sort the eigenvalues and eigenvectors in descending order\n",
    "        sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "        sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "        sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "\n",
    "        # Select the top n_components eigenvectors\n",
    "        top_eigenvectors = sorted_eigenvectors[:, :self.n_components]\n",
    "\n",
    "        # Project the data onto the lower-dimensional space\n",
    "        X_reduced = X_standardized.dot(top_eigenvectors)\n",
    "        return X_reduced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv(\"../../data/lung_cancer/RSEM_gene_expression.csv\")\n",
    "label = pd.read_csv(\"../../data/lung_cancer/label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>TCGA.38.4625.11A.01R.1758.07</th>\n",
       "      <th>TCGA.38.4626.11A.01R.1758.07</th>\n",
       "      <th>TCGA.38.4627.11A.01R.1758.07</th>\n",
       "      <th>TCGA.38.4632.11A.01R.1755.07</th>\n",
       "      <th>TCGA.44.2655.11A.01R.1758.07</th>\n",
       "      <th>TCGA.44.2657.11A.01R.1758.07</th>\n",
       "      <th>TCGA.44.2661.11A.01R.1758.07</th>\n",
       "      <th>TCGA.44.2662.11A.01R.1758.07</th>\n",
       "      <th>TCGA.44.2665.11A.01R.1758.07</th>\n",
       "      <th>...</th>\n",
       "      <th>TCGA.55.6985.01A.11R.1949.07</th>\n",
       "      <th>TCGA.55.6986.01A.11R.1949.07</th>\n",
       "      <th>TCGA.73.4676.01A.01R.1755.07</th>\n",
       "      <th>TCGA.91.6828.01A.11R.1858.07</th>\n",
       "      <th>TCGA.91.6829.01A.21R.1858.07</th>\n",
       "      <th>TCGA.91.6831.01A.11R.1858.07</th>\n",
       "      <th>TCGA.91.6835.01A.11R.1858.07</th>\n",
       "      <th>TCGA.91.6836.01A.21R.1858.07</th>\n",
       "      <th>TCGA.91.6847.01A.11R.1949.07</th>\n",
       "      <th>TCGA.91.6849.01A.11R.1949.07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1BG</td>\n",
       "      <td>2.376951</td>\n",
       "      <td>2.389110</td>\n",
       "      <td>2.567027</td>\n",
       "      <td>1.984067</td>\n",
       "      <td>1.940027</td>\n",
       "      <td>2.145310</td>\n",
       "      <td>1.876524</td>\n",
       "      <td>1.718150</td>\n",
       "      <td>2.020237</td>\n",
       "      <td>...</td>\n",
       "      <td>2.385953</td>\n",
       "      <td>1.476131</td>\n",
       "      <td>1.539658</td>\n",
       "      <td>1.338952</td>\n",
       "      <td>1.906988</td>\n",
       "      <td>2.251477</td>\n",
       "      <td>1.678886</td>\n",
       "      <td>1.156658</td>\n",
       "      <td>1.967031</td>\n",
       "      <td>1.448140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1CF</td>\n",
       "      <td>0.138208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195678</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.158694</td>\n",
       "      <td>0.127979</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2BP1</td>\n",
       "      <td>0.327155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.187182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.168645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.379070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964212</td>\n",
       "      <td>0.237217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.563965</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A2LD1</td>\n",
       "      <td>1.966153</td>\n",
       "      <td>1.784606</td>\n",
       "      <td>2.047704</td>\n",
       "      <td>2.191235</td>\n",
       "      <td>1.764270</td>\n",
       "      <td>1.839508</td>\n",
       "      <td>1.852457</td>\n",
       "      <td>1.787285</td>\n",
       "      <td>1.917105</td>\n",
       "      <td>...</td>\n",
       "      <td>1.908085</td>\n",
       "      <td>1.985155</td>\n",
       "      <td>2.238298</td>\n",
       "      <td>1.901524</td>\n",
       "      <td>1.758846</td>\n",
       "      <td>1.636331</td>\n",
       "      <td>1.893888</td>\n",
       "      <td>1.636736</td>\n",
       "      <td>2.073938</td>\n",
       "      <td>2.029682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2ML1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135101</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.590039</td>\n",
       "      <td>0.208522</td>\n",
       "      <td>1.708297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.310757</td>\n",
       "      <td>...</td>\n",
       "      <td>0.242119</td>\n",
       "      <td>0.591843</td>\n",
       "      <td>0.619740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.486430</td>\n",
       "      <td>0.248415</td>\n",
       "      <td>0.663861</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.885027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19010</th>\n",
       "      <td>ZYX</td>\n",
       "      <td>3.912519</td>\n",
       "      <td>3.914306</td>\n",
       "      <td>3.952002</td>\n",
       "      <td>3.766593</td>\n",
       "      <td>4.087053</td>\n",
       "      <td>3.906192</td>\n",
       "      <td>3.998028</td>\n",
       "      <td>4.185095</td>\n",
       "      <td>3.950831</td>\n",
       "      <td>...</td>\n",
       "      <td>3.640447</td>\n",
       "      <td>3.690902</td>\n",
       "      <td>3.583560</td>\n",
       "      <td>3.450641</td>\n",
       "      <td>3.663913</td>\n",
       "      <td>3.420016</td>\n",
       "      <td>3.643462</td>\n",
       "      <td>3.680469</td>\n",
       "      <td>3.688148</td>\n",
       "      <td>3.563819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19011</th>\n",
       "      <td>ZZEF1</td>\n",
       "      <td>2.953984</td>\n",
       "      <td>3.049674</td>\n",
       "      <td>2.743782</td>\n",
       "      <td>3.037380</td>\n",
       "      <td>3.210946</td>\n",
       "      <td>3.240631</td>\n",
       "      <td>3.245352</td>\n",
       "      <td>3.209613</td>\n",
       "      <td>3.222442</td>\n",
       "      <td>...</td>\n",
       "      <td>3.014765</td>\n",
       "      <td>3.105009</td>\n",
       "      <td>2.686129</td>\n",
       "      <td>3.082395</td>\n",
       "      <td>3.102380</td>\n",
       "      <td>3.046834</td>\n",
       "      <td>3.236373</td>\n",
       "      <td>2.904206</td>\n",
       "      <td>2.724101</td>\n",
       "      <td>3.098511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19012</th>\n",
       "      <td>ZZZ3</td>\n",
       "      <td>2.663086</td>\n",
       "      <td>2.611265</td>\n",
       "      <td>2.694675</td>\n",
       "      <td>2.948180</td>\n",
       "      <td>2.731388</td>\n",
       "      <td>2.692122</td>\n",
       "      <td>2.730854</td>\n",
       "      <td>2.602218</td>\n",
       "      <td>2.638635</td>\n",
       "      <td>...</td>\n",
       "      <td>2.807565</td>\n",
       "      <td>2.871417</td>\n",
       "      <td>3.017495</td>\n",
       "      <td>2.863797</td>\n",
       "      <td>2.923707</td>\n",
       "      <td>2.851406</td>\n",
       "      <td>2.919495</td>\n",
       "      <td>2.995623</td>\n",
       "      <td>3.020199</td>\n",
       "      <td>2.753724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19013</th>\n",
       "      <td>psiTPTE22</td>\n",
       "      <td>2.236097</td>\n",
       "      <td>2.412022</td>\n",
       "      <td>2.061549</td>\n",
       "      <td>1.755033</td>\n",
       "      <td>2.100769</td>\n",
       "      <td>2.057899</td>\n",
       "      <td>1.869624</td>\n",
       "      <td>2.330615</td>\n",
       "      <td>2.307690</td>\n",
       "      <td>...</td>\n",
       "      <td>1.963999</td>\n",
       "      <td>1.248344</td>\n",
       "      <td>2.624337</td>\n",
       "      <td>1.230278</td>\n",
       "      <td>1.428347</td>\n",
       "      <td>1.339201</td>\n",
       "      <td>2.358102</td>\n",
       "      <td>0.441601</td>\n",
       "      <td>0.226703</td>\n",
       "      <td>1.366365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19014</th>\n",
       "      <td>tAKR</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19015 rows Ã 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Gene  TCGA.38.4625.11A.01R.1758.07  TCGA.38.4626.11A.01R.1758.07   \n",
       "0           A1BG                      2.376951                      2.389110  \\\n",
       "1           A1CF                      0.138208                      0.000000   \n",
       "2          A2BP1                      0.327155                      0.000000   \n",
       "3          A2LD1                      1.966153                      1.784606   \n",
       "4          A2ML1                      0.000000                      0.135101   \n",
       "...          ...                           ...                           ...   \n",
       "19010        ZYX                      3.912519                      3.914306   \n",
       "19011      ZZEF1                      2.953984                      3.049674   \n",
       "19012       ZZZ3                      2.663086                      2.611265   \n",
       "19013  psiTPTE22                      2.236097                      2.412022   \n",
       "19014       tAKR                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.38.4627.11A.01R.1758.07  TCGA.38.4632.11A.01R.1755.07   \n",
       "0                          2.567027                      1.984067  \\\n",
       "1                          0.000000                      0.000000   \n",
       "2                          0.187182                      0.000000   \n",
       "3                          2.047704                      2.191235   \n",
       "4                          0.000000                      0.590039   \n",
       "...                             ...                           ...   \n",
       "19010                      3.952002                      3.766593   \n",
       "19011                      2.743782                      3.037380   \n",
       "19012                      2.694675                      2.948180   \n",
       "19013                      2.061549                      1.755033   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.44.2655.11A.01R.1758.07  TCGA.44.2657.11A.01R.1758.07   \n",
       "0                          1.940027                      2.145310  \\\n",
       "1                          0.000000                      0.195678   \n",
       "2                          0.116674                      0.000000   \n",
       "3                          1.764270                      1.839508   \n",
       "4                          0.208522                      1.708297   \n",
       "...                             ...                           ...   \n",
       "19010                      4.087053                      3.906192   \n",
       "19011                      3.210946                      3.240631   \n",
       "19012                      2.731388                      2.692122   \n",
       "19013                      2.100769                      2.057899   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.44.2661.11A.01R.1758.07  TCGA.44.2662.11A.01R.1758.07   \n",
       "0                          1.876524                      1.718150  \\\n",
       "1                          0.000000                      0.000000   \n",
       "2                          0.168645                      0.000000   \n",
       "3                          1.852457                      1.787285   \n",
       "4                          0.000000                      0.000000   \n",
       "...                             ...                           ...   \n",
       "19010                      3.998028                      4.185095   \n",
       "19011                      3.245352                      3.209613   \n",
       "19012                      2.730854                      2.602218   \n",
       "19013                      1.869624                      2.330615   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.44.2665.11A.01R.1758.07  ...  TCGA.55.6985.01A.11R.1949.07   \n",
       "0                          2.020237  ...                      2.385953  \\\n",
       "1                          0.000000  ...                      0.000000   \n",
       "2                          0.379070  ...                      0.964212   \n",
       "3                          1.917105  ...                      1.908085   \n",
       "4                          0.310757  ...                      0.242119   \n",
       "...                             ...  ...                           ...   \n",
       "19010                      3.950831  ...                      3.640447   \n",
       "19011                      3.222442  ...                      3.014765   \n",
       "19012                      2.638635  ...                      2.807565   \n",
       "19013                      2.307690  ...                      1.963999   \n",
       "19014                      0.000000  ...                      0.000000   \n",
       "\n",
       "       TCGA.55.6986.01A.11R.1949.07  TCGA.73.4676.01A.01R.1755.07   \n",
       "0                          1.476131                      1.539658  \\\n",
       "1                          0.000000                      0.000000   \n",
       "2                          0.237217                      0.000000   \n",
       "3                          1.985155                      2.238298   \n",
       "4                          0.591843                      0.619740   \n",
       "...                             ...                           ...   \n",
       "19010                      3.690902                      3.583560   \n",
       "19011                      3.105009                      2.686129   \n",
       "19012                      2.871417                      3.017495   \n",
       "19013                      1.248344                      2.624337   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.91.6828.01A.11R.1858.07  TCGA.91.6829.01A.21R.1858.07   \n",
       "0                          1.338952                      1.906988  \\\n",
       "1                          0.000000                      0.000000   \n",
       "2                          0.000000                      0.180785   \n",
       "3                          1.901524                      1.758846   \n",
       "4                          0.000000                      0.486430   \n",
       "...                             ...                           ...   \n",
       "19010                      3.450641                      3.663913   \n",
       "19011                      3.082395                      3.102380   \n",
       "19012                      2.863797                      2.923707   \n",
       "19013                      1.230278                      1.428347   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.91.6831.01A.11R.1858.07  TCGA.91.6835.01A.11R.1858.07   \n",
       "0                          2.251477                      1.678886  \\\n",
       "1                          0.000000                      0.000000   \n",
       "2                          0.000000                      0.000000   \n",
       "3                          1.636331                      1.893888   \n",
       "4                          0.248415                      0.663861   \n",
       "...                             ...                           ...   \n",
       "19010                      3.420016                      3.643462   \n",
       "19011                      3.046834                      3.236373   \n",
       "19012                      2.851406                      2.919495   \n",
       "19013                      1.339201                      2.358102   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.91.6836.01A.21R.1858.07  TCGA.91.6847.01A.11R.1949.07   \n",
       "0                          1.156658                      1.967031  \\\n",
       "1                          0.158694                      0.127979   \n",
       "2                          0.000000                      1.563965   \n",
       "3                          1.636736                      2.073938   \n",
       "4                          0.000000                      0.000000   \n",
       "...                             ...                           ...   \n",
       "19010                      3.680469                      3.688148   \n",
       "19011                      2.904206                      2.724101   \n",
       "19012                      2.995623                      3.020199   \n",
       "19013                      0.441601                      0.226703   \n",
       "19014                      0.000000                      0.000000   \n",
       "\n",
       "       TCGA.91.6849.01A.11R.1949.07  \n",
       "0                          1.448140  \n",
       "1                          0.000000  \n",
       "2                          0.000000  \n",
       "3                          2.029682  \n",
       "4                          0.885027  \n",
       "...                             ...  \n",
       "19010                      3.563819  \n",
       "19011                      3.098511  \n",
       "19012                      2.753724  \n",
       "19013                      1.366365  \n",
       "19014                      0.000000  \n",
       "\n",
       "[19015 rows x 117 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data overview\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Disease</th>\n",
       "      <th>Class</th>\n",
       "      <th>Patient</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>TCGA.38.4625.11A.01R.1758.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>TCGA.38.4626.11A.01R.1758.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>TCGA.38.4627.11A.01R.1758.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>TCGA.38.4632.11A.01R.1755.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>TCGA.44.2655.11A.01R.1758.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>tumor</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>TCGA.91.6831.01A.11R.1858.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tumor</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "      <td>TCGA.91.6835.01A.11R.1858.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>tumor</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>TCGA.91.6836.01A.21R.1858.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>tumor</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>TCGA.91.6847.01A.11R.1949.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>tumor</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>TCGA.91.6849.01A.11R.1949.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows Ã 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Disease  Class  Patient                            ID\n",
       "0    normal      0        1  TCGA.38.4625.11A.01R.1758.07\n",
       "1    normal      0        2  TCGA.38.4626.11A.01R.1758.07\n",
       "2    normal      0        3  TCGA.38.4627.11A.01R.1758.07\n",
       "3    normal      0        4  TCGA.38.4632.11A.01R.1755.07\n",
       "4    normal      0        5  TCGA.44.2655.11A.01R.1758.07\n",
       "..      ...    ...      ...                           ...\n",
       "111   tumor      1       54  TCGA.91.6831.01A.11R.1858.07\n",
       "112   tumor      1       55  TCGA.91.6835.01A.11R.1858.07\n",
       "113   tumor      1       56  TCGA.91.6836.01A.21R.1858.07\n",
       "114   tumor      1       57  TCGA.91.6847.01A.11R.1949.07\n",
       "115   tumor      1       58  TCGA.91.6849.01A.11R.1949.07\n",
       "\n",
       "[116 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label overview\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape (116, 19015)\n"
     ]
    }
   ],
   "source": [
    "# Remove the first column and transpose the data\n",
    "X = data.iloc[:, 1:].values.T\n",
    "\n",
    "print(\"Shape\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to the dataset, reducing the dimensionality to 2\n",
    "pca = PCA(n_components=2)\n",
    "X_reduced = pca.fit_transform(X)\n",
    "\n",
    "X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'c' argument has 116 elements, which is inconsistent with 'x' and 'y' with size 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4439\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4438\u001b[0m \u001b[39mtry\u001b[39;00m:  \u001b[39m# Is 'c' acceptable as PathCollection facecolors?\u001b[39;00m\n\u001b[0;32m-> 4439\u001b[0m     colors \u001b[39m=\u001b[39m mcolors\u001b[39m.\u001b[39;49mto_rgba_array(c)\n\u001b[1;32m   4440\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36mto_rgba_array\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/colors.py:487\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 487\u001b[0m     rgba \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([to_rgba(cc) \u001b[39mfor\u001b[39;00m cc \u001b[39min\u001b[39;00m c])\n\u001b[1;32m    489\u001b[0m \u001b[39mif\u001b[39;00m alpha \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/colors.py:299\u001b[0m, in \u001b[0;36mto_rgba\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m rgba \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:  \u001b[39m# Suppress exception chaining of cache lookup failure.\u001b[39;00m\n\u001b[0;32m--> 299\u001b[0m     rgba \u001b[39m=\u001b[39m _to_rgba_no_colorcycle(c, alpha)\n\u001b[1;32m    300\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/colors.py:381\u001b[0m, in \u001b[0;36m_to_rgba_no_colorcycle\u001b[0;34m(c, alpha)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39miterable(c):\n\u001b[0;32m--> 381\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid RGBA argument: \u001b[39m\u001b[39m{\u001b[39;00morig_c\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(c) \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m3\u001b[39m, \u001b[39m4\u001b[39m]:\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid RGBA argument: 0.0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[76], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m fig, (ax1, ax2) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(ncols\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m))\n\u001b[1;32m      4\u001b[0m \u001b[39m# Plot the MSE over the epochs\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m ax1\u001b[39m.\u001b[39;49mscatter(X_reduced[\u001b[39m0\u001b[39;49m], X_reduced[\u001b[39m1\u001b[39;49m], c\u001b[39m=\u001b[39;49mlabel[\u001b[39m'\u001b[39;49m\u001b[39mClass\u001b[39;49m\u001b[39m'\u001b[39;49m], cmap\u001b[39m=\u001b[39;49mplt\u001b[39m.\u001b[39;49mcm\u001b[39m.\u001b[39;49mtab10)\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/__init__.py:1442\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m   1440\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(ax, \u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1441\u001b[0m     \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1442\u001b[0m         \u001b[39mreturn\u001b[39;00m func(ax, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(sanitize_sequence, args), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1444\u001b[0m     bound \u001b[39m=\u001b[39m new_sig\u001b[39m.\u001b[39mbind(ax, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1445\u001b[0m     auto_label \u001b[39m=\u001b[39m (bound\u001b[39m.\u001b[39marguments\u001b[39m.\u001b[39mget(label_namer)\n\u001b[1;32m   1446\u001b[0m                   \u001b[39mor\u001b[39;00m bound\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4602\u001b[0m, in \u001b[0;36mAxes.scatter\u001b[0;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, edgecolors, plotnonfinite, **kwargs)\u001b[0m\n\u001b[1;32m   4599\u001b[0m \u001b[39mif\u001b[39;00m edgecolors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4600\u001b[0m     orig_edgecolor \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39medgecolor\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4601\u001b[0m c, colors, edgecolors \u001b[39m=\u001b[39m \\\n\u001b[0;32m-> 4602\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_scatter_color_args(\n\u001b[1;32m   4603\u001b[0m         c, edgecolors, kwargs, x\u001b[39m.\u001b[39;49msize,\n\u001b[1;32m   4604\u001b[0m         get_next_color_func\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_patches_for_fill\u001b[39m.\u001b[39;49mget_next_color)\n\u001b[1;32m   4606\u001b[0m \u001b[39mif\u001b[39;00m plotnonfinite \u001b[39mand\u001b[39;00m colors \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   4607\u001b[0m     c \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mma\u001b[39m.\u001b[39mmasked_invalid(c)\n",
      "File \u001b[0;32m~/Desktop/INDE577/DataScience-MachineLearning/.venv/lib/python3.9/site-packages/matplotlib/axes/_axes.py:4445\u001b[0m, in \u001b[0;36mAxes._parse_scatter_color_args\u001b[0;34m(c, edgecolors, kwargs, xsize, get_next_color_func)\u001b[0m\n\u001b[1;32m   4443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   4444\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m valid_shape:\n\u001b[0;32m-> 4445\u001b[0m         \u001b[39mraise\u001b[39;00m invalid_shape_exception(c\u001b[39m.\u001b[39msize, xsize) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   4446\u001b[0m     \u001b[39m# Both the mapping *and* the RGBA conversion failed: pretty\u001b[39;00m\n\u001b[1;32m   4447\u001b[0m     \u001b[39m# severe failure => one may appreciate a verbose feedback.\u001b[39;00m\n\u001b[1;32m   4448\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   4449\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument must be a color, a sequence of colors, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4450\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mor a sequence of numbers, not \u001b[39m\u001b[39m{\u001b[39;00mc\u001b[39m!r}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: 'c' argument has 116 elements, which is inconsistent with 'x' and 'y' with size 2."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot results\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot the MSE over the epochs\n",
    "ax1.scatter(X_reduced[0], X_reduced[1], c=label['Class'], cmap=plt.cm.tab10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label['Class'].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
