{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "The Perceptron is a binary classification algorithm introduced by Frank Rosenblatt in 1957. It is a type of artificial neuron and one of the earliest machine learning models. The Perceptron can be used for linearly separable datasets and is the foundation for many modern neural networks.\n",
    "\n",
    "## History\n",
    "\n",
    "The Perceptron was first proposed by Frank Rosenblatt in 1957 while he was working at the Cornell Aeronautical Laboratory. The algorithm was inspired by the way biological neurons work and aimed to create a simple model that could be used for pattern recognition tasks.\n",
    "\n",
    "## Mathematical Equations\n",
    "\n",
    "The Perceptron computes a linear combination of input features and a bias term. The resulting value is passed through an activation function to produce the output.\n",
    "\n",
    "`output = activation(sum(w_i * x_i) + b)`\n",
    "\n",
    "The activation function for the Perceptron is a step function:\n",
    "\n",
    "`activation(x) = 1 if x > 0 else 0`\n",
    "\n",
    "### Weight Update Rule\n",
    "\n",
    "If an instance is misclassified, update the weights and bias as follows:\n",
    "\n",
    "`w_i = w_i + learning_rate * (target - output) * x_i`\n",
    "\n",
    "`b = b + learning_rate * (target - output)`\n",
    "\n",
    "## Learning Algorithm\n",
    "\n",
    "1. Initialize the weights and bias to zero or small random values.\n",
    "2. For each training instance:\n",
    "   - Compute the output using the activation function.\n",
    "   - Update the weights and bias if the output is not correct.\n",
    "3. Repeat step 2 for the desired number of epochs or until convergence.\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- Simple and easy to implement.\n",
    "- Efficient for linearly separable data.\n",
    "- Can be used as a building block for more complex models (e.g., multi-layer perceptrons).\n",
    "\n",
    "**Cons:**\n",
    "- Cannot solve non-linearly separable problems.\n",
    "- Sensitive to the choice of learning rate and initial weights.\n",
    "- No guarantee of convergence for non-linearly separable data.\n",
    "\n",
    "## Suitable Tasks and Datasets\n",
    "\n",
    "The Perceptron is best suited for linearly separable datasets and binary classification tasks. Some examples include:\n",
    "- Predicting whether an email is spam or not.\n",
    "- Classifying handwritten digits (0 and 1).\n",
    "- Separating two different types of plants based on their features.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Rosenblatt, F. (1958). The perceptron: A probabilistic model for information storage and organization in the brain. Psychological Review, 65(6), 386-408.\n",
    "2. Minsky, M., & Papert, S. (1969). Perceptrons: An introduction to computational geometry. MIT Press.\n",
    "3. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, n_features, learning_rate=0.01, epochs=1000):\n",
    "        self.n_features = n_features\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        return np.where(linear_output > 0, 1, 0)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.epochs):\n",
    "            for xi, target in zip(X, y):\n",
    "                output = self.predict(xi)\n",
    "                update = self.learning_rate * (target - output)\n",
    "                self.weights += update * xi\n",
    "                self.bias += update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the Iris dataset and prepare the binary classification data\n",
    "data = load_iris()\n",
    "X, y = data.data[:100], data.target[:100]\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Perceptron\n",
    "perceptron = Perceptron(n_features=X_train.shape[1], learning_rate=0.01, epochs=1000)\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and calculate accuracy\n",
    "predictions = perceptron.predict(X_test)\n",
    "accuracy = np.mean(predictions == y_test)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
