{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "# Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Mathematical Fundations](#mathematical-fundations)\n",
    "    1. [Weight Update Rule](#weight-update-rule)\n",
    "3. [Learning Algorithm](#learning-algorithm)\n",
    "      1. [Write a Perceptron Class](#write-a-perceptron-class-based-on-the-above-algorithm)\n",
    "      2. [Showcase the above Perceptron Class in iris dataset](#showcase-the-above-perceptron-class-in-iris-dataset)\n",
    "      3. [Use the Perceptron class provided by Scikit-Learn](#use-the-perceptron-class-provided-by-scikit-learn)\n",
    "4. [Pros and Cons](#pros-and-cons)\n",
    "5. [Suitable Tasks and Datasets](#suitable-tasks-and-datasets)\n",
    "6. [References](#references)\n",
    "\n",
    "Gradient descent is an optimization algorithm used to find the minimum of a function. It is commonly used in machine learning and deep learning to minimize the loss function and update the model's parameters.\n",
    "\n",
    "## History\n",
    "\n",
    "Gradient descent was first proposed by Cauchy in 1847. It has since been widely used in optimization problems, particularly in the field of machine learning, where it has become one of the most popular algorithms for training models.\n",
    "\n",
    "## Mathematical Equations\n",
    "\n",
    "Given a function `f(w)`, where `w` is a vector of parameters, the gradient descent algorithm aims to find the minimum of the function. The gradient of the function (∇f(w)) represents the direction of the steepest increase in the function's value. The update rule for gradient descent is:\n",
    "\n",
    "w(t+1) = w(t) - η * ∇f(w(t))\n",
    "\n",
    "where:\n",
    "- w(t): The parameter vector at iteration t.\n",
    "- η: The learning rate, which controls the step size in each iteration.\n",
    "- ∇f(w(t)): The gradient of the function evaluated at w(t).\n",
    "\n",
    "The learning rate η is a hyperparameter that needs to be tuned. If it is too small, the algorithm will converge slowly, while if it is too large, it may overshoot the minimum and diverge.\n",
    "\n",
    "## Learning Algorithm\n",
    "\n",
    "The learning algorithm for gradient descent consists of iteratively updating the model's parameters by following the negative gradient of the loss function. The main steps are:\n",
    "\n",
    "1. Initialize the model's parameters randomly or using a predefined method.\n",
    "2. Calculate the gradient of the loss function with respect to each parameter.\n",
    "3. Update the parameters using the gradient descent update rule.\n",
    "4. Repeat steps 2 and 3 until a stopping criterion is met (e.g., maximum number of iterations, minimum change in the loss function, or minimum change in the parameters).\n",
    "\n",
    "## Pros and Cons\n",
    "\n",
    "**Pros:**\n",
    "- Simple and easy to understand.\n",
    "- Can be applied to a wide range of problems.\n",
    "- Efficient for large-scale datasets and problems with many parameters.\n",
    "- Can be adapted to use adaptive learning rates or momentum.\n",
    "\n",
    "**Cons:**\n",
    "- Sensitive to the choice of learning rate and other hyperparameters.\n",
    "- Can get stuck in local minima for non-convex functions.\n",
    "- May be slow to converge for ill-conditioned problems or problems with a high degree of curvature.\n",
    "- Requires the calculation of gradients, which can be computationally expensive for complex models.\n",
    "\n",
    "## Suitable Tasks and Datasets\n",
    "\n",
    "Gradient descent can be applied to a wide range of optimization tasks in machine learning and deep learning, including:\n",
    "\n",
    "- Linear regression\n",
    "- Logistic regression\n",
    "- Neural networks\n",
    "- Support vector machines (with the appropriate kernel and loss function)\n",
    "\n",
    "It is particularly useful for problems with large datasets or a high number of parameters, where other optimization algorithms may be too computationally expensive.\n",
    "\n",
    "## References\n",
    "\n",
    "1. Cauchy, A. (1847). Méthode générale pour la résolution des systèmes d'équations simultanées. Comptes Rendus, 25, 536-538.\n",
    "2. Bottou, L. (2010). Large-scale machine learning with stochastic gradient descent. In Proceedings of the 19th International Conference on Computational Statistics (pp. 177-186). Springer.\n",
    "3. Ruder, S. (2016). An overview of gradient descent optimization algorithms. arXiv preprint arXiv:1609.04747.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Gradient Descent is an optimization algorithm that's used when training a machine learning model. It's based on a simple idea: To find a local minimum of a function, start at a random point, and move in the direction of steepest descent—opposite to the gradient of the function at the current point.\n",
    "\n",
    "## Steps Involved:\n",
    "\n",
    "1. **Initialize**: Start with random values for the parameters.\n",
    "\n",
    "2. **Compute Gradient**: Calculate the gradient of the cost function with respect to each parameter.\n",
    "\n",
    "3. **Update Parameters**: Update each parameter by subtracting the product of the learning rate and the gradient of the cost function with respect to that parameter.\n",
    "\n",
    "4. **Iterate**: Repeat steps 2 and 3 until the algorithm converges to a minimum.\n",
    "\n",
    "## Types of Gradient Descent:\n",
    "\n",
    "1. **Batch Gradient Descent**: Uses all training samples in each iteration of the training algorithm.\n",
    "\n",
    "2. **Stochastic Gradient Descent (SGD)**: Uses only one training sample in each iteration of the training algorithm.\n",
    "\n",
    "3. **Mini-Batch Gradient Descent**: Uses a subset of training samples in each iteration of the training algorithm.\n",
    "\n",
    "The type of Gradient Descent used can affect the speed and quality of the learning process.\n",
    "\n",
    "## Learning Rate:\n",
    "\n",
    "The learning rate, often denoted by `α`, is a hyperparameter that determines the step size at each iteration while moving toward a minimum of the cost function. If the learning rate is too small, the algorithm takes a long time to converge; if it's too large, the algorithm might overshoot the minimum and fail to converge.\n",
    "\n",
    "In practice, finding a good learning rate often requires trial and error.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenges with Gradient Descent:\n",
    "\n",
    "1. **Local Minima**: For some functions, there may be multiple places where the gradient is zero (minima). Gradient descent is a local optimization method, which means it can get stuck in a sub-optimal local minimum, rather than finding the global minimum.\n",
    "\n",
    "2. **Saddle Points**: These are points where all derivatives are zero but are not a local minimum or maximum. The algorithm can get stuck in these points, especially in high-dimensional spaces.\n",
    "\n",
    "3. **Slow Convergence**: In some cases, if the learning rate is too small or if the function is badly scaled (e.g., more curved in one dimension than in another), then gradient descent can converge very slowly to the minimum.\n",
    "\n",
    "4. **Choosing the Right Learning Rate**: If the learning rate is too high, gradient descent can overshoot the minimum and may fail to converge, or even diverge. If the learning rate is too low, the algorithm will eventually reach the minimum, but it might take too much time.\n",
    "\n",
    "5. **Dependency on Initial Values**: The initial values of the parameters can impact the solution, especially in the presence of local minima. Different initial values can lead to different solutions.\n",
    "\n",
    "Despite these challenges, Gradient Descent is a foundational algorithm in machine learning and deep learning and is used to train many models due to its simplicity and efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class GradientDescent:\n",
    "    def __init__(self, learning_rate=0.01, max_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iterations = max_iterations\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Add a column of ones to X for the bias term\n",
    "        X = np.hstack((np.ones((n_samples, 1)), X))\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights = np.random.rand(n_features + 1)\n",
    "\n",
    "        # Perform gradient descent\n",
    "        for _ in range(self.max_iterations):\n",
    "            gradient = (2 / n_samples) * X.T.dot(X.dot(self.weights) - y)\n",
    "            self.weights -= self.learning_rate * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X = np.hstack((np.ones((n_samples, 1)), X))\n",
    "        return X.dot(self.weights)\n",
    "\n",
    "# Generate a synthetic regression dataset\n",
    "X, y = make_regression(n_samples=100, n_features=1, noise=20, random_state=42)\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model using gradient descent\n",
    "model = GradientDescent(learning_rate=0.1, max_iterations=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "\n",
    "# Visualize the results\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.scatter(X_test, y_pred, color='red', label='Predicted')\n",
    "plt.legend()\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression using Gradient Descent')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# This code defines a simple gradient descent class and applies it to linear regression. The learning rate and maximum number of iterations are hyperparameters that can be adjusted. In this example, we use a learning rate of 0.1 and 1000 iterations. The model is evaluated on a test set using mean squared error, and the results are visualized in a scatter plot.\n",
    "\n",
    "The learning rate is an important hyperparameter that affects the convergence of the gradient descent algorithm. If it is too small, the algorithm may converge slowly or get stuck in a local minimum. If it is too large, the algorithm may overshoot the minimum and diverge. Experimenting with different learning rates can help find the optimal value for a given problem."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
